{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data sets and combine them into a single usable dataframe called data series\n",
    "data_series = pd.read_csv('./data/data_avg_temp.csv')\n",
    "\n",
    "# rename columns to be more descriptive\n",
    "data_series.columns = ['date', 'avg_temp', 'avg_temp_anomaly']\n",
    "data_series.drop(columns=['avg_temp_anomaly'], inplace=True)\n",
    "\n",
    "# append to the dataframe\n",
    "data_cool_degree = pd.read_csv('./data/data_cool_degree_days.csv')\n",
    "data_heat_degree = pd.read_csv('./data/data_heat_degree_days.csv')\n",
    "data_max_temp = pd.read_csv('./data/data_max_temp.csv')\n",
    "data_min_temp = pd.read_csv('./data/data_min_temp.csv')\n",
    "data_palmer_z = pd.read_csv('./data/data_palmer_z.csv')\n",
    "data_pdsi = pd.read_csv('./data/data_pdsi.csv')\n",
    "data_phdi = pd.read_csv('./data/data_phdi.csv')\n",
    "data_pmdi = pd.read_csv('./data/data_pmdi.csv')\n",
    "data_precipitation = pd.read_csv('./data/data_precipitation.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Append columns to the data series\n",
    "data_series['cool_degree_days'] = data_cool_degree['Value']\n",
    "# data_series['cool_degree_days_anomaly'] = data_cool_degree['Anomaly']\n",
    "\n",
    "data_series['heat_degree_days'] = data_heat_degree['Value']\n",
    "# data_series['heat_degree_days_anomaly'] = data_heat_degree['Anomaly']\n",
    "\n",
    "data_series['max_temp'] = data_max_temp['Value']\n",
    "# data_series['max_temp_anomaly'] = data_max_temp['Anomaly']\n",
    "\n",
    "data_series['min_temp'] = data_min_temp['Value']\n",
    "# data_series['min_temp_anomaly'] = data_min_temp['Anomaly']\n",
    "\n",
    "data_series['palmer_z'] = data_palmer_z['Value']\n",
    "# data_series['palmer_z_anomaly'] = data_palmer_z['Anomaly']\n",
    "\n",
    "data_series['pdsi'] = data_pdsi['Value']\n",
    "# data_series['pdsi_anomaly'] = data_pdsi['Anomaly']\n",
    "\n",
    "data_series['phdi'] = data_phdi['Value']\n",
    "# data_series['phdi_anomaly'] = data_phdi['Anomaly']\n",
    "\n",
    "data_series['pmdi'] = data_pmdi['Value']\n",
    "# data_series['pmdi_anomaly'] = data_pmdi['Anomaly']\n",
    "\n",
    "data_series['precipitation'] = data_precipitation['Value']\n",
    "# data_series['precipitation_anomaly'] = data_precipitation['Anomaly']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to numpy array\n",
    "avg_temp = data_series['avg_temp'].to_numpy()\n",
    "data_series.drop(columns=['avg_temp'], inplace=True)\n",
    "\n",
    "x = data_series.to_numpy()\n",
    "\n",
    "# Expand first dim\n",
    "x = np.expand_dims(x, axis=0)\n",
    "avg_temp = np.expand_dims(avg_temp, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GRU model\n",
    "model_gru = Sequential(\n",
    "    [\n",
    "        GRU(20, activation='relu', input_shape=(x.shape[1], x.shape[2])),\n",
    "        Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_gru.compile(optimizer='adam', loss='mse')\n",
    "model_gru.fit(x, avg_temp, epochs=300, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the temperature by regressing the other features and then predicting average temperature\n",
    "parameters = ['cool_degree_days', 'heat_degree_days', 'max_temp', \n",
    "              'min_temp', 'palmer_z', 'pdsi',\n",
    "              'phdi', 'pmdi', 'precipitation']\n",
    "# parameters = ['cool_degree_days']\n",
    "models = {}\n",
    "scalers = {}\n",
    "\n",
    "date = data_series['date'].to_numpy()\n",
    "date_splice = np.zeros((len(date), 2))\n",
    "\n",
    "param_models = []\n",
    "\n",
    "for i, element in enumerate(date):\n",
    "    # print(element)\n",
    "    # Splice this string to get year and month\n",
    "    date_splice[i,0] = int(str(element)[0:4])\n",
    "    date_splice[i,1] = int(str(element)[5:7])\n",
    "\n",
    "for param in parameters:\n",
    "    print(f\"PARAM\", param)\n",
    "    y = data_series[param].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(date_splice, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(5, activation='relu', input_shape=(X_train.shape[1],)),  # input_shape=(2,)\n",
    "        Dense(1)  # Output layer\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Save model\n",
    "    param_models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of the average temperature\n",
    "# Using the trained models to predict the parameters and then use those predictions as input for the GRU model\n",
    "\n",
    "# Predict the parameters for the next 5 year * 12 months (60 datapoints)\n",
    "\n",
    "# Get dates for prediction (202401-202812)\n",
    "years = 60\n",
    "date_predict = np.zeros((years*12, 2))\n",
    "for i in range(years*12):\n",
    "    date_predict[i, 0] = 2024 + i // 12\n",
    "    date_predict[i, 1] = 1 + i % 12\n",
    "\n",
    "\n",
    "param_predicts = np.zeros((len(parameters),years*12))\n",
    "\n",
    "#  Predict the parameters.\n",
    "for k, model in enumerate(param_models):\n",
    "    for i in range(years*12):\n",
    "        answer = model.predict(date_predict[i].reshape(1, -1))\n",
    "        param_predicts[k, i] = answer\n",
    "\n",
    "yearmonth_vec = np.zeros((years*12,1))\n",
    "for i in range(years*12):\n",
    "    yearmonth_vec[i] = date_predict[i, 0] * 100 + date_predict[i, 1]\n",
    "\n",
    "params_predicts = np.append(yearmonth_vec, param_predicts.T, axis=1)\n",
    "\n",
    "print(params_predicts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(years*12):\n",
    "    print(f\"Year: {int(params_predicts[i,0]//100)} Month: {int(params_predicts[i,0]%100)}\")\n",
    "    print(f\"Predicted parameters:\")\n",
    "    for j, param in enumerate(parameters):\n",
    "        print(f\"{param}: {params_predicts[i,j+1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use predicted params for GRU input to predict avg_temp\n",
    "predictions = []\n",
    "\n",
    "for i in range(years*12):\n",
    "    new_timestep = params_predicts[i,:]\n",
    "    new_timestep = np.expand_dims(new_timestep, axis=0)\n",
    "    x = np.append(x[:,1:,:], np.expand_dims(new_timestep, axis=0), axis=1)\n",
    "\n",
    "    # x = np.expand_dims(params_predicts[i, :], axis=0)\n",
    "    avg_temp_predict = model_gru.predict(x)\n",
    "    predictions.append(avg_temp_predict)\n",
    "\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "plt.plot(yearmonth_vec[2:], predictions[2:], label='Predicted')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_new_mexico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
